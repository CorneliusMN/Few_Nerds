{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"DFKI-SLT/few-nerd\", \"inter\") # you can set to supervised, inter and intra\n",
    "\n",
    "# inter: same coarse-grained categories\n",
    "# intra: different coarse-grained categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130112, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dataset[\"train\"]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18817, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = dataset[\"validation\"] \n",
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14007, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = dataset[\"test\"] \n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER and fine NER tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'art',\n",
       " 'building',\n",
       " 'event',\n",
       " 'location',\n",
       " 'organization',\n",
       " 'other',\n",
       " 'person',\n",
       " 'product']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tags = train.features[\"ner_tags\"].feature.names\n",
    "ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the index of a tag given the tag\n",
    "index_person = ner_tags.index(\"person\")\n",
    "index_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'art-broadcastprogram',\n",
       " 'art-film',\n",
       " 'art-music',\n",
       " 'art-other',\n",
       " 'art-painting',\n",
       " 'art-writtenart',\n",
       " 'building-airport',\n",
       " 'building-hospital',\n",
       " 'building-hotel',\n",
       " 'building-library',\n",
       " 'building-other',\n",
       " 'building-restaurant',\n",
       " 'building-sportsfacility',\n",
       " 'building-theater',\n",
       " 'event-attack/battle/war/militaryconflict',\n",
       " 'event-disaster',\n",
       " 'event-election',\n",
       " 'event-other',\n",
       " 'event-protest',\n",
       " 'event-sportsevent',\n",
       " 'location-GPE',\n",
       " 'location-bodiesofwater',\n",
       " 'location-island',\n",
       " 'location-mountain',\n",
       " 'location-other',\n",
       " 'location-park',\n",
       " 'location-road/railway/highway/transit',\n",
       " 'organization-company',\n",
       " 'organization-education',\n",
       " 'organization-government/governmentagency',\n",
       " 'organization-media/newspaper',\n",
       " 'organization-other',\n",
       " 'organization-politicalparty',\n",
       " 'organization-religion',\n",
       " 'organization-showorganization',\n",
       " 'organization-sportsleague',\n",
       " 'organization-sportsteam',\n",
       " 'other-astronomything',\n",
       " 'other-award',\n",
       " 'other-biologything',\n",
       " 'other-chemicalthing',\n",
       " 'other-currency',\n",
       " 'other-disease',\n",
       " 'other-educationaldegree',\n",
       " 'other-god',\n",
       " 'other-language',\n",
       " 'other-law',\n",
       " 'other-livingthing',\n",
       " 'other-medical',\n",
       " 'person-actor',\n",
       " 'person-artist/author',\n",
       " 'person-athlete',\n",
       " 'person-director',\n",
       " 'person-other',\n",
       " 'person-politician',\n",
       " 'person-scholar',\n",
       " 'person-soldier',\n",
       " 'product-airplane',\n",
       " 'product-car',\n",
       " 'product-food',\n",
       " 'product-game',\n",
       " 'product-other',\n",
       " 'product-ship',\n",
       " 'product-software',\n",
       " 'product-train',\n",
       " 'product-weapon']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_ner_tags = train.features[\"fine_ner_tags\"].feature.names\n",
    "fine_ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as before but with fine NER\n",
    "index_event_election = fine_ner_tags.index(\"event-election\")\n",
    "index_event_election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closer look at the (training) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '10',\n",
       " 'tokens': ['The',\n",
       "  'City',\n",
       "  'of',\n",
       "  'Bradenton',\n",
       "  'talked',\n",
       "  'A',\n",
       "  \"'s\",\n",
       "  'owner',\n",
       "  'Charlie',\n",
       "  'Finley',\n",
       "  'into',\n",
       "  'staying',\n",
       "  'at',\n",
       "  'McKechnie',\n",
       "  'until',\n",
       "  '.'],\n",
       " 'ner_tags': [0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0],\n",
       " 'fine_ner_tags': [0, 21, 21, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 0, 0]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[10].get(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'City',\n",
       " 'of',\n",
       " 'Bradenton',\n",
       " 'talked',\n",
       " 'A',\n",
       " \"'s\",\n",
       " 'owner',\n",
       " 'Charlie',\n",
       " 'Finley',\n",
       " 'into',\n",
       " 'staying',\n",
       " 'at',\n",
       " 'McKechnie',\n",
       " 'until',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[10].get(\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[10].get(\"ner_tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 21, 21, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 0, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[10].get(\"fine_ner_tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0]\n",
      "O\n",
      "location\n",
      "location\n",
      "location\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "organization\n",
      "O\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "train_10_ner_tags = train[10].get(\"ner_tags\")\n",
    "print(train_10_ner_tags)\n",
    "\n",
    "for i in train_10_ner_tags:\n",
    "    print(ner_tags[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 21, 21, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 0, 0]\n",
      "O\n",
      "location-GPE\n",
      "location-GPE\n",
      "location-GPE\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "organization-sportsleague\n",
      "O\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "train_10_fine_ner_tags = train[10].get(\"fine_ner_tags\")\n",
    "print(train_10_fine_ner_tags)\n",
    "\n",
    "for i in train_10_fine_ner_tags:\n",
    "    print(fine_ner_tags[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to work only with fine grained NER tags of a single category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences containing only the specified ner tag: 9622\n"
     ]
    }
   ],
   "source": [
    "# Only keep the sentences having person as ner tag\n",
    "ner_tag_index = ner_tags.index(\"person\")\n",
    "\n",
    "def filter_only_person(example):\n",
    "\n",
    "    has_ner_tag = False\n",
    "    for tag in example[\"ner_tags\"]:\n",
    "        # skip non-entity tokens\n",
    "        if tag == 0:\n",
    "            continue\n",
    "        if tag != ner_tag_index:\n",
    "            return False\n",
    "        else:\n",
    "            has_person = True\n",
    "    return has_person\n",
    "\n",
    "# Filter the dataset\n",
    "filtered_train_person = dataset[\"train\"].filter(filter_only_person)\n",
    "\n",
    "print(\"Number of sentences containing only the specified ner tag:\", len(filtered_train_person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '15',\n",
       " 'tokens': ['Sherman',\n",
       "  'had',\n",
       "  'suffered',\n",
       "  'from',\n",
       "  'several',\n",
       "  'health',\n",
       "  'problems',\n",
       "  ',',\n",
       "  'including',\n",
       "  'kidney',\n",
       "  'ailments',\n",
       "  ',',\n",
       "  'and',\n",
       "  'injuries',\n",
       "  'from',\n",
       "  'a',\n",
       "  'car',\n",
       "  'accident',\n",
       "  'several',\n",
       "  'weeks',\n",
       "  'before',\n",
       "  'his',\n",
       "  'death',\n",
       "  'may',\n",
       "  'have',\n",
       "  'contributed',\n",
       "  'to',\n",
       "  'his',\n",
       "  'declining',\n",
       "  'health',\n",
       "  '.'],\n",
       " 'ner_tags': [7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'fine_ner_tags': [55,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_person[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sherman',\n",
       " 'had',\n",
       " 'suffered',\n",
       " 'from',\n",
       " 'several',\n",
       " 'health',\n",
       " 'problems',\n",
       " ',',\n",
       " 'including',\n",
       " 'kidney',\n",
       " 'ailments',\n",
       " ',',\n",
       " 'and',\n",
       " 'injuries',\n",
       " 'from',\n",
       " 'a',\n",
       " 'car',\n",
       " 'accident',\n",
       " 'several',\n",
       " 'weeks',\n",
       " 'before',\n",
       " 'his',\n",
       " 'death',\n",
       " 'may',\n",
       " 'have',\n",
       " 'contributed',\n",
       " 'to',\n",
       " 'his',\n",
       " 'declining',\n",
       " 'health',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_person[0].get(\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_person[0].get(\"ner_tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'person'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tags[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_person[0].get(\"fine_ner_tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'location-GPE'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_ner_tags[21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want multiple ner tags (I made this part working with the **inter** dataset, so the second function doesn't work in this case since now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences containing only the specified ner tags: 49134\n"
     ]
    }
   ],
   "source": [
    "person_index = ner_tags.index(\"person\")\n",
    "location_index = ner_tags.index(\"location\")\n",
    "\n",
    "def filter_person_or_location(example):\n",
    "    has_valid_ner_tag = False\n",
    "    for tag in example[\"ner_tags\"]:\n",
    "        if tag == 0:\n",
    "            continue\n",
    "        if tag != person_index and tag != location_index:\n",
    "            return False\n",
    "        has_valid_ner_tag = True\n",
    "    return has_valid_ner_tag # only keep if at least one valid entity tag is found\n",
    "\n",
    "filtered_train_person_location = dataset[\"train\"].filter(filter_person_or_location)\n",
    "\n",
    "print(\"Number of sentences containing only the specified ner tags:\", len(filtered_train_person_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_person_location[0].get(\"ner_tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both train and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences containing both the ner tags: 6220\n"
     ]
    }
   ],
   "source": [
    "def contains_both_person_and_location(example):\n",
    "    has_person = False\n",
    "    has_location = False\n",
    "    for tag in example[\"ner_tags\"]:\n",
    "        if tag == person_index:\n",
    "            has_person = True\n",
    "        elif tag == location_index:\n",
    "            has_location = True\n",
    "        # If both are true\n",
    "        if has_person and has_location:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "filtered_both = filtered_train_person_location.filter(contains_both_person_and_location)\n",
    "\n",
    "print(\"Number of sentences containing both the ner tags:\", len(filtered_both))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_both[0].get(\"ner_tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentences containing at least one coarse-grained label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24148 sentences contain a PERSON token\n"
     ]
    }
   ],
   "source": [
    "# filter to only sentences where at least one token is tagged PERSON\n",
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "train_person = train.filter(lambda ex: index_person in ex[\"ner_tags\"])\n",
    "\n",
    "print(f\"{len(train_person)} sentences contain a PERSON token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11359 sentences contain a PRODUCT token\n"
     ]
    }
   ],
   "source": [
    "# filter to only sentences where at least one token is tagged PRODUCT\n",
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "train_product = train.filter(lambda ex: index_product in ex[\"ner_tags\"])\n",
    "\n",
    "print(f\"{len(train_product)} sentences contain a PRODUCT token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46631 sentences contain a ORGANIZATION token\n"
     ]
    }
   ],
   "source": [
    "# filter to only sentences where at least one token is tagged ORGANIZATION\n",
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "train_organization = train.filter(lambda ex: index_organization in ex[\"ner_tags\"])\n",
    "\n",
    "print(f\"{len(train_organization)} sentences contain a ORGANIZATION token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.087301709296606\n",
      "0.18559394982784064\n",
      "0.35839123216920804\n"
     ]
    }
   ],
   "source": [
    "# percentages\n",
    "print(len(train_product)/len(train))\n",
    "print(len(train_person)/len(train))\n",
    "print(len(train_organization)/len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of examples of a specific coarse-grained lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PRODUCT labels in train: 39653\n"
     ]
    }
   ],
   "source": [
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "total_product_labels = sum(tags.count(index_product) for tags in train[\"ner_tags\"])\n",
    "\n",
    "print(f\"Total number of PRODUCT labels in train: {total_product_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PERSON labels in train: 68321\n"
     ]
    }
   ],
   "source": [
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "total_person_labels = sum(tags.count(index_person) for tags in train[\"ner_tags\"])\n",
    "\n",
    "print(f\"Total number of PERSON labels in train: {total_person_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of ORGANIZATION labels in train: 183962\n"
     ]
    }
   ],
   "source": [
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "total_organization_labels = sum(tags.count(index_organization) for tags in train[\"ner_tags\"])\n",
    "\n",
    "print(f\"Total number of ORGANIZATION labels in train: {total_organization_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentences containing at least one fine-grained label within a coarse-grained one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained product type:\n",
      "product-airplane → 2409\n",
      "product-car → 0\n",
      "product-food → 1080\n",
      "product-game → 0\n",
      "product-other → 4841\n",
      "product-ship → 1450\n",
      "product-software → 2123\n",
      "product-train → 0\n",
      "product-weapon → 0\n"
     ]
    }
   ],
   "source": [
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "product_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"product\")]\n",
    "\n",
    "train_product = train.filter(lambda ex: index_product in ex[\"ner_tags\"])\n",
    "\n",
    "counts = {}\n",
    "for lbl in product_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    # count sentences where this fine tag appears at least once\n",
    "    counts[lbl] = sum(1 for tags in train_product[\"fine_ner_tags\"] if idx_lbl in tags)\n",
    "\n",
    "print(\"Sentence counts per fine‑grained product type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained person type:\n",
      "person-actor → 0\n",
      "person-artist/author → 10494\n",
      "person-athlete → 0\n",
      "person-director → 2403\n",
      "person-other → 0\n",
      "person-politician → 9547\n",
      "person-scholar → 0\n",
      "person-soldier → 2614\n"
     ]
    }
   ],
   "source": [
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "person_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"person\")]\n",
    "\n",
    "train_person = train.filter(lambda ex: index_person in ex[\"ner_tags\"])\n",
    "\n",
    "counts = {}\n",
    "for lbl in person_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    # count sentences where this fine tag appears at least once\n",
    "    counts[lbl] = sum(1 for tags in train_person[\"fine_ner_tags\"] if idx_lbl in tags)\n",
    "\n",
    "print(\"Sentence counts per fine‑grained person type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained organization type:\n",
      "organization-company → 12890\n",
      "organization-education → 7472\n",
      "organization-government/governmentagency → 0\n",
      "organization-media/newspaper → 4109\n",
      "organization-other → 15225\n",
      "organization-politicalparty → 0\n",
      "organization-religion → 0\n",
      "organization-showorganization → 0\n",
      "organization-sportsleague → 3296\n",
      "organization-sportsteam → 8329\n"
     ]
    }
   ],
   "source": [
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "organization_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"organization\")]\n",
    "\n",
    "train_organization = train.filter(lambda ex: index_organization in ex[\"ner_tags\"])\n",
    "\n",
    "counts = {}\n",
    "for lbl in organization_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    # count sentences where this fine tag appears at least once\n",
    "    counts[lbl] = sum(1 for tags in train_organization[\"fine_ner_tags\"] if idx_lbl in tags)\n",
    "\n",
    "print(\"Sentence counts per fine‑grained organization type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of examples of a specific fine-grained lable within a given coarse-grained one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained product type:\n",
      "product-airplane → 8306\n",
      "product-car → 0\n",
      "product-food → 3863\n",
      "product-game → 0\n",
      "product-other → 16198\n",
      "product-ship → 3756\n",
      "product-software → 7530\n",
      "product-train → 0\n",
      "product-weapon → 0\n"
     ]
    }
   ],
   "source": [
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "product_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"product\")]\n",
    "\n",
    "train_product = train.filter(lambda ex: index_product in ex[\"ner_tags\"])\n",
    "\n",
    "# sum up all occurrences of each fine label\n",
    "counts = {}\n",
    "for lbl in product_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    total_lbl = sum(tags.count(idx_lbl) for tags in train_product[\"fine_ner_tags\"])\n",
    "    counts[lbl] = total_lbl\n",
    "\n",
    "print(\"Sentence counts per fine‑grained product type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained person type:\n",
      "person-actor → 0\n",
      "person-artist/author → 31553\n",
      "person-athlete → 0\n",
      "person-director → 5795\n",
      "person-other → 0\n",
      "person-politician → 24898\n",
      "person-scholar → 0\n",
      "person-soldier → 6075\n"
     ]
    }
   ],
   "source": [
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "person_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"person\")]\n",
    "\n",
    "train_person = train.filter(lambda ex: index_person in ex[\"ner_tags\"])\n",
    "\n",
    "# sum up all occurrences of each fine label\n",
    "counts = {}\n",
    "for lbl in person_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    total_lbl = sum(tags.count(idx_lbl) for tags in train_person[\"fine_ner_tags\"])\n",
    "    counts[lbl] = total_lbl\n",
    "\n",
    "print(\"Sentence counts per fine‑grained person type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained organization type:\n",
      "organization-company → 41167\n",
      "organization-education → 33839\n",
      "organization-government/governmentagency → 0\n",
      "organization-media/newspaper → 11969\n",
      "organization-other → 61718\n",
      "organization-politicalparty → 0\n",
      "organization-religion → 0\n",
      "organization-showorganization → 0\n",
      "organization-sportsleague → 10824\n",
      "organization-sportsteam → 24445\n"
     ]
    }
   ],
   "source": [
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "organization_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"organization\")]\n",
    "\n",
    "train_organization = train.filter(lambda ex: index_organization in ex[\"ner_tags\"])\n",
    "\n",
    "# sum up all occurrences of each fine label\n",
    "counts = {}\n",
    "for lbl in organization_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    total_lbl = sum(tags.count(idx_lbl) for tags in train_organization[\"fine_ner_tags\"])\n",
    "    counts[lbl] = total_lbl\n",
    "\n",
    "print(\"Sentence counts per fine‑grained organization type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats on DEV (VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381 sentences contain a PERSON token\n"
     ]
    }
   ],
   "source": [
    "# filter to only sentences where at least one token is tagged PERSON\n",
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "val_person = val.filter(lambda ex: index_person in ex[\"ner_tags\"])\n",
    "\n",
    "print(f\"{len(val_person)} sentences contain a PERSON token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963 sentences contain a PRODUCT token\n"
     ]
    }
   ],
   "source": [
    "# filter to only sentences where at least one token is tagged PRODUCT\n",
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "val_product = val.filter(lambda ex: index_product in ex[\"ner_tags\"])\n",
    "\n",
    "print(f\"{len(val_product)} sentences contain a PRODUCT token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570 sentences contain a ORGANIZATION token\n"
     ]
    }
   ],
   "source": [
    "# filter to only sentences where at least one token is tagged ORGANIZATION\n",
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "val_organization = val.filter(lambda ex: index_organization in ex[\"ner_tags\"])\n",
    "\n",
    "print(f\"{len(val_organization)} sentences contain a ORGANIZATION token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051177127065951004\n",
      "0.5516819896901738\n",
      "0.08343519158208003\n"
     ]
    }
   ],
   "source": [
    "# percentages\n",
    "print(len(val_product)/len(val))\n",
    "print(len(val_person)/len(val))\n",
    "print(len(val_organization)/len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PRODUCT labels in val: 3957\n"
     ]
    }
   ],
   "source": [
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "total_product_labels = sum(tags.count(index_product) for tags in val[\"ner_tags\"])\n",
    "\n",
    "print(f\"Total number of PRODUCT labels in val: {total_product_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PERSON labels in val: 29357\n"
     ]
    }
   ],
   "source": [
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "total_person_labels = sum(tags.count(index_person) for tags in val[\"ner_tags\"])\n",
    "\n",
    "print(f\"Total number of PERSON labels in val: {total_person_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of ORGANIZATION labels in val: 5147\n"
     ]
    }
   ],
   "source": [
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "total_organization_labels = sum(tags.count(index_organization) for tags in val[\"ner_tags\"])\n",
    "\n",
    "print(f\"Total number of ORGANIZATION labels in val: {total_organization_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained product type:\n",
      "product-airplane → 0\n",
      "product-car → 0\n",
      "product-food → 0\n",
      "product-game → 582\n",
      "product-other → 0\n",
      "product-ship → 0\n",
      "product-software → 0\n",
      "product-train → 381\n",
      "product-weapon → 0\n"
     ]
    }
   ],
   "source": [
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "product_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"product\")]\n",
    "\n",
    "val_product = val.filter(lambda ex: index_product in ex[\"ner_tags\"])\n",
    "\n",
    "counts = {}\n",
    "for lbl in product_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    # count sentences where this fine tag appears at least once\n",
    "    counts[lbl] = sum(1 for tags in val_product[\"fine_ner_tags\"] if idx_lbl in tags)\n",
    "\n",
    "print(\"Sentence counts per fine‑grained product type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained person type:\n",
      "person-actor → 0\n",
      "person-artist/author → 0\n",
      "person-athlete → 0\n",
      "person-director → 0\n",
      "person-other → 9628\n",
      "person-politician → 0\n",
      "person-scholar → 835\n",
      "person-soldier → 0\n"
     ]
    }
   ],
   "source": [
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "person_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"person\")]\n",
    "\n",
    "val_person = val.filter(lambda ex: index_person in ex[\"ner_tags\"])\n",
    "\n",
    "counts = {}\n",
    "for lbl in person_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    # count sentences where this fine tag appears at least once\n",
    "    counts[lbl] = sum(1 for tags in val_person[\"fine_ner_tags\"] if idx_lbl in tags)\n",
    "\n",
    "print(\"Sentence counts per fine‑grained person type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained organization type:\n",
      "organization-company → 0\n",
      "organization-education → 0\n",
      "organization-government/governmentagency → 0\n",
      "organization-media/newspaper → 0\n",
      "organization-other → 0\n",
      "organization-politicalparty → 0\n",
      "organization-religion → 938\n",
      "organization-showorganization → 638\n",
      "organization-sportsleague → 0\n",
      "organization-sportsteam → 0\n"
     ]
    }
   ],
   "source": [
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "organization_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"organization\")]\n",
    "\n",
    "val_organization = val.filter(lambda ex: index_organization in ex[\"ner_tags\"])\n",
    "\n",
    "counts = {}\n",
    "for lbl in organization_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    # count sentences where this fine tag appears at least once\n",
    "    counts[lbl] = sum(1 for tags in val_organization[\"fine_ner_tags\"] if idx_lbl in tags)\n",
    "\n",
    "print(\"Sentence counts per fine‑grained organization type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained product type:\n",
      "product-airplane → 0\n",
      "product-car → 0\n",
      "product-food → 0\n",
      "product-game → 2384\n",
      "product-other → 0\n",
      "product-ship → 0\n",
      "product-software → 0\n",
      "product-train → 1573\n",
      "product-weapon → 0\n"
     ]
    }
   ],
   "source": [
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "product_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"product\")]\n",
    "\n",
    "val_product = val.filter(lambda ex: index_product in ex[\"ner_tags\"])\n",
    "\n",
    "# sum up all occurrences of each fine label\n",
    "counts = {}\n",
    "for lbl in product_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    total_lbl = sum(tags.count(idx_lbl) for tags in val_product[\"fine_ner_tags\"])\n",
    "    counts[lbl] = total_lbl\n",
    "\n",
    "print(\"Sentence counts per fine‑grained product type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained person type:\n",
      "person-actor → 0\n",
      "person-artist/author → 0\n",
      "person-athlete → 0\n",
      "person-director → 0\n",
      "person-other → 27328\n",
      "person-politician → 0\n",
      "person-scholar → 2029\n",
      "person-soldier → 0\n"
     ]
    }
   ],
   "source": [
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "person_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"person\")]\n",
    "\n",
    "val_person = val.filter(lambda ex: index_person in ex[\"ner_tags\"])\n",
    "\n",
    "# sum up all occurrences of each fine label\n",
    "counts = {}\n",
    "for lbl in person_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    total_lbl = sum(tags.count(idx_lbl) for tags in val_person[\"fine_ner_tags\"])\n",
    "    counts[lbl] = total_lbl\n",
    "\n",
    "print(\"Sentence counts per fine‑grained person type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained organization type:\n",
      "organization-company → 0\n",
      "organization-education → 0\n",
      "organization-government/governmentagency → 0\n",
      "organization-media/newspaper → 0\n",
      "organization-other → 0\n",
      "organization-politicalparty → 0\n",
      "organization-religion → 2903\n",
      "organization-showorganization → 2244\n",
      "organization-sportsleague → 0\n",
      "organization-sportsteam → 0\n"
     ]
    }
   ],
   "source": [
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "organization_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"organization\")]\n",
    "\n",
    "val_organization = val.filter(lambda ex: index_organization in ex[\"ner_tags\"])\n",
    "\n",
    "# sum up all occurrences of each fine label\n",
    "counts = {}\n",
    "for lbl in organization_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    total_lbl = sum(tags.count(idx_lbl) for tags in val_organization[\"fine_ner_tags\"])\n",
    "    counts[lbl] = total_lbl\n",
    "\n",
    "print(\"Sentence counts per fine‑grained organization type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats on TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3761 sentences contain a PERSON token\n"
     ]
    }
   ],
   "source": [
    "# filter to only sentences where at least one token is tagged PERSON\n",
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "test_person = test.filter(lambda ex: index_person in ex[\"ner_tags\"])\n",
    "\n",
    "print(f\"{len(test_person)} sentences contain a PERSON token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425 sentences contain a PRODUCT token\n"
     ]
    }
   ],
   "source": [
    "# filter to only sentences where at least one token is tagged PRODUCT\n",
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "test_product = test.filter(lambda ex: index_product in ex[\"ner_tags\"])\n",
    "\n",
    "print(f\"{len(test_product)} sentences contain a PRODUCT token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992 sentences contain a ORGANIZATION token\n"
     ]
    }
   ],
   "source": [
    "# filter to only sentences where at least one token is tagged ORGANIZATION\n",
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "test_organization = test.filter(lambda ex: index_organization in ex[\"ner_tags\"])\n",
    "\n",
    "print(f\"{len(test_organization)} sentences contain a ORGANIZATION token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10173484686228314\n",
      "0.2685086028414364\n",
      "0.14221460698222319\n"
     ]
    }
   ],
   "source": [
    "# percentages\n",
    "print(len(test_product)/len(test))\n",
    "print(len(test_person)/len(test))\n",
    "print(len(test_organization)/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PRODUCT labels in test: 6013\n"
     ]
    }
   ],
   "source": [
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "total_product_labels = sum(tags.count(index_product) for tags in test[\"ner_tags\"])\n",
    "\n",
    "print(f\"Total number of PRODUCT labels in test: {total_product_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of PERSON labels in test: 13330\n"
     ]
    }
   ],
   "source": [
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "total_person_labels = sum(tags.count(index_person) for tags in test[\"ner_tags\"])\n",
    "\n",
    "print(f\"Total number of PERSON labels in test: {total_person_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of ORGANIZATION labels in test: 8815\n"
     ]
    }
   ],
   "source": [
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "total_organization_labels = sum(tags.count(index_organization) for tags in test[\"ner_tags\"])\n",
    "\n",
    "print(f\"Total number of ORGANIZATION labels in test: {total_organization_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained product type:\n",
      "product-airplane → 0\n",
      "product-car → 762\n",
      "product-food → 0\n",
      "product-game → 0\n",
      "product-other → 0\n",
      "product-ship → 0\n",
      "product-software → 0\n",
      "product-train → 0\n",
      "product-weapon → 671\n"
     ]
    }
   ],
   "source": [
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "product_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"product\")]\n",
    "\n",
    "test_product = test.filter(lambda ex: index_product in ex[\"ner_tags\"])\n",
    "\n",
    "counts = {}\n",
    "for lbl in product_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    # count sentences where this fine tag appears at least once\n",
    "    counts[lbl] = sum(1 for tags in test_product[\"fine_ner_tags\"] if idx_lbl in tags)\n",
    "\n",
    "print(\"Sentence counts per fine‑grained product type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained person type:\n",
      "person-actor → 822\n",
      "person-artist/author → 0\n",
      "person-athlete → 2945\n",
      "person-director → 0\n",
      "person-other → 0\n",
      "person-politician → 0\n",
      "person-scholar → 0\n",
      "person-soldier → 0\n"
     ]
    }
   ],
   "source": [
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "person_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"person\")]\n",
    "\n",
    "test_person = test.filter(lambda ex: index_person in ex[\"ner_tags\"])\n",
    "\n",
    "counts = {}\n",
    "for lbl in person_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    # count sentences where this fine tag appears at least once\n",
    "    counts[lbl] = sum(1 for tags in test_person[\"fine_ner_tags\"] if idx_lbl in tags)\n",
    "\n",
    "print(\"Sentence counts per fine‑grained person type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained organization type:\n",
      "organization-company → 0\n",
      "organization-education → 0\n",
      "organization-government/governmentagency → 1340\n",
      "organization-media/newspaper → 0\n",
      "organization-other → 0\n",
      "organization-politicalparty → 769\n",
      "organization-religion → 0\n",
      "organization-showorganization → 0\n",
      "organization-sportsleague → 0\n",
      "organization-sportsteam → 0\n"
     ]
    }
   ],
   "source": [
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "organization_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"organization\")]\n",
    "\n",
    "test_organization = test.filter(lambda ex: index_organization in ex[\"ner_tags\"])\n",
    "\n",
    "counts = {}\n",
    "for lbl in organization_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    # count sentences where this fine tag appears at least once\n",
    "    counts[lbl] = sum(1 for tags in test_organization[\"fine_ner_tags\"] if idx_lbl in tags)\n",
    "\n",
    "print(\"Sentence counts per fine‑grained organization type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained product type:\n",
      "product-airplane → 0\n",
      "product-car → 3178\n",
      "product-food → 0\n",
      "product-game → 0\n",
      "product-other → 0\n",
      "product-ship → 0\n",
      "product-software → 0\n",
      "product-train → 0\n",
      "product-weapon → 2835\n"
     ]
    }
   ],
   "source": [
    "index_product = ner_tags.index(\"product\")\n",
    "\n",
    "product_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"product\")]\n",
    "\n",
    "test_product = test.filter(lambda ex: index_product in ex[\"ner_tags\"])\n",
    "\n",
    "# sum up all occurrences of each fine label\n",
    "counts = {}\n",
    "for lbl in product_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    total_lbl = sum(tags.count(idx_lbl) for tags in test_product[\"fine_ner_tags\"])\n",
    "    counts[lbl] = total_lbl\n",
    "\n",
    "print(\"Sentence counts per fine‑grained product type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained person type:\n",
      "person-actor → 4142\n",
      "person-artist/author → 0\n",
      "person-athlete → 9188\n",
      "person-director → 0\n",
      "person-other → 0\n",
      "person-politician → 0\n",
      "person-scholar → 0\n",
      "person-soldier → 0\n"
     ]
    }
   ],
   "source": [
    "index_person = ner_tags.index(\"person\")\n",
    "\n",
    "person_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"person\")]\n",
    "\n",
    "test_person = test.filter(lambda ex: index_person in ex[\"ner_tags\"])\n",
    "\n",
    "# sum up all occurrences of each fine label\n",
    "counts = {}\n",
    "for lbl in person_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    total_lbl = sum(tags.count(idx_lbl) for tags in test_person[\"fine_ner_tags\"])\n",
    "    counts[lbl] = total_lbl\n",
    "\n",
    "print(\"Sentence counts per fine‑grained person type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence counts per fine‑grained organization type:\n",
      "organization-company → 0\n",
      "organization-education → 0\n",
      "organization-government/governmentagency → 5464\n",
      "organization-media/newspaper → 0\n",
      "organization-other → 0\n",
      "organization-politicalparty → 3351\n",
      "organization-religion → 0\n",
      "organization-showorganization → 0\n",
      "organization-sportsleague → 0\n",
      "organization-sportsteam → 0\n"
     ]
    }
   ],
   "source": [
    "index_organization = ner_tags.index(\"organization\")\n",
    "\n",
    "organization_fine_labels = [lbl for lbl in fine_ner_tags if lbl.startswith(\"organization\")]\n",
    "\n",
    "test_organization = test.filter(lambda ex: index_organization in ex[\"ner_tags\"])\n",
    "\n",
    "# sum up all occurrences of each fine label\n",
    "counts = {}\n",
    "for lbl in organization_fine_labels:\n",
    "    idx_lbl = fine_ner_tags.index(lbl)\n",
    "    total_lbl = sum(tags.count(idx_lbl) for tags in test_organization[\"fine_ner_tags\"])\n",
    "    counts[lbl] = total_lbl\n",
    "\n",
    "print(\"Sentence counts per fine‑grained organization type:\")\n",
    "for lbl, cnt in counts.items():\n",
    "    print(f\"{lbl} → {cnt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
